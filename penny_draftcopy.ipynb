{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lkhart/football_penny_app/blob/main/penny_draftcopy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNckc5joauJN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from scipy.optimize import minimize\n",
        "from shapely import Polygon, Point\n",
        "import itertools\n",
        "import numpy as np\n",
        "import random\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OffensivePlayer:\n",
        "    def __init__(self, route_points, speed):\n",
        "        self.route_points = route_points\n",
        "        self.speed = speed\n",
        "\n",
        "    def get_position_at_time(self, t_step):\n",
        "        return self.calculate_positions(selected_frame=t_step)\n",
        "\n",
        "    def get_direction_at_time(self, t_step):\n",
        "        t = t_step/10\n",
        "        total_time = sum([dist/self.speed for dist in [np.linalg.norm(np.array(self.route_points[i+1]) - np.array(self.route_points[i])) for i in range(len(self.route_points)-1)]])\n",
        "\n",
        "        #if the time requested is beyond the end of the route:\n",
        "        if t > total_time:\n",
        "            start_y = self.route_points[0][1]\n",
        "            #direction towards the x=0 line at the player's starting y-coordinate\n",
        "            direction = np.rad2deg(np.arctan2(0 - self.route_points[-1][1], start_y - self.route_points[-1][0]))\n",
        "            return direction\n",
        "\n",
        "        prevstep = t_step - 1\n",
        "        loc_minus1 = tuple(self.calculate_positions(selected_frame=prevstep))\n",
        "        loc_curr = tuple(self.calculate_positions(selected_frame=t_step))\n",
        "\n",
        "        def angle_between_off(p1, p2):\n",
        "            dy = p2[1] - p1[1]\n",
        "            dx = p2[0] - p1[0]\n",
        "            angle_rad = np.arctan2(dy, dx)\n",
        "            angle_deg = np.degrees(angle_rad)\n",
        "            return (angle_deg + 360) % 360\n",
        "\n",
        "        direction = angle_between(loc_minus1, loc_curr)\n",
        "        return direction\n",
        "\n",
        "\n",
        "    def calculate_positions(self, time_duration_per_step=0.1, play_frames=50, selected_frame=None):\n",
        "        playerspeed = self.speed*10\n",
        "        total_play_time = play_frames * time_duration_per_step\n",
        "\n",
        "        segment_distances = [np.linalg.norm(np.array(self.route_points[i+1]) - np.array(self.route_points[i]))\n",
        "                             for i in range(len(self.route_points)-1)]\n",
        "        segment_times = [dist/playerspeed for dist in segment_distances]\n",
        "\n",
        "        time_intervals = np.arange(0, total_play_time, time_duration_per_step)\n",
        "\n",
        "        current_segment = 0\n",
        "        current_position = np.array(self.route_points[0], dtype=float)\n",
        "        positions = [current_position]\n",
        "\n",
        "        for t in time_intervals[1:]:\n",
        "            if current_segment < len(segment_distances):\n",
        "                direction_vector = np.array(self.route_points[current_segment+1]) - np.array(self.route_points[current_segment])\n",
        "                direction_vector = direction_vector.astype(float)\n",
        "                direction_vector /= np.linalg.norm(direction_vector)\n",
        "\n",
        "                segment_elapsed_time = t - sum(segment_times[:current_segment])\n",
        "                movement_distance = segment_elapsed_time * playerspeed\n",
        "                new_position = np.array(self.route_points[current_segment]) + direction_vector * movement_distance\n",
        "\n",
        "                #check if the calculated new_position has overshot the current segment's endpoint\n",
        "                if np.linalg.norm(new_position - self.route_points[current_segment]) > segment_distances[current_segment]:\n",
        "                    current_segment += 1\n",
        "                    if current_segment < len(segment_distances):\n",
        "                        residual_distance = movement_distance - segment_distances[current_segment - 1]\n",
        "                        direction_vector = np.array(self.route_points[current_segment+1]) - np.array(self.route_points[current_segment])\n",
        "                        direction_vector = direction_vector.astype(float)\n",
        "                        direction_vector /= np.linalg.norm(direction_vector)\n",
        "                        new_position = np.array(self.route_points[current_segment]) + direction_vector * residual_distance\n",
        "                    else:\n",
        "                        new_position = self.route_points[-1]\n",
        "                positions.append(list(new_position))\n",
        "            else:\n",
        "                positions.append(self.route_points[-1])\n",
        "\n",
        "        if len(positions) > play_frames:\n",
        "            positions = positions[:play_frames]\n",
        "        elif len(positions) < play_frames:\n",
        "            positions.extend([positions[-1]] * (play_frames - len(positions)))\n",
        "\n",
        "        rounded_positions = [(round(pos[0], 2), round(pos[1], 2)) for pos in positions]\n",
        "\n",
        "        if selected_frame == None:\n",
        "            return rounded_positions\n",
        "        else:\n",
        "            return rounded_positions[selected_frame]"
      ],
      "metadata": {
        "id": "DEeUllFBazve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_offensive_position_off(off_player, t_step, reaction_time=2):\n",
        "\n",
        "    past_step = t_step-reaction_time\n",
        "\n",
        "    #get the player's direction and position at the past time step\n",
        "    past_direction_deg = off_player.get_direction_at_time(past_step)\n",
        "    past_position = off_player.calculate_positions(selected_frame=past_step)\n",
        "\n",
        "    #convert the direction from degrees to a unit vector\n",
        "    past_direction_rad = np.radians(past_direction_deg)\n",
        "    direction_vector = np.array([np.cos(past_direction_rad), np.sin(past_direction_rad)])\n",
        "\n",
        "    #predict the new position based on speed and direction\n",
        "    distance_moved = off_player.speed * reaction_time # speed * time\n",
        "    predicted_position = past_position + (direction_vector * distance_moved)\n",
        "\n",
        "    return (round(predicted_position[0], 2), round(predicted_position[1], 2))"
      ],
      "metadata": {
        "id": "rbzzR3nba2D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_offensive_position(off_players, time_step):\n",
        "    full_list = list(tuple(singleoff.calculate_positions(selected_frame=time_step)) for singleoff in off_players)\n",
        "    return full_list\n",
        "\n",
        "#need to address ts=1\n",
        "#ts=49 should be closer given angle of direction of the player\n",
        "def full_offensive_position_pred(off_players, time_step):\n",
        "    full_list = list(tuple(predict_offensive_position_off(singleoff, time_step)) for singleoff in off_players)\n",
        "    return full_list"
      ],
      "metadata": {
        "id": "WfoGdHmVa3zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DefensivePlayer:\n",
        "    def __init__(self, start_position, speed, allowable_area, current_position=None):\n",
        "        self.start_position = np.array(start_position)\n",
        "        if current_position is None:\n",
        "            self.position = np.array(start_position)\n",
        "        else:\n",
        "            self.position = np.array(current_position)\n",
        "        self.speed = speed\n",
        "        self.allowable_area = allowable_area  #polygon object\n",
        "\n",
        "    def get_position(self):\n",
        "        return self.position\n",
        "\n",
        "    def reset_position(self):\n",
        "        self.position = np.array(start_position)\n",
        "\n",
        "    def move(self, new_position):\n",
        "        self.position = np.array(new_position)\n",
        "\n",
        "    def distance_to(self, offensive_player, t_step=0):\n",
        "        other_position = offensive_player.get_position_at_time(t_step)  #assuming t is the current time\n",
        "        return np.linalg.norm(self.position - np.array(other_position))\n",
        "\n",
        "    def relation_to_receiver_direction(self, theta_r, off_player_loc):\n",
        "\n",
        "        #compute direction to defensive player\n",
        "        theta_d = angle_between(off_player_loc, self.position)\n",
        "\n",
        "        #angle difference\n",
        "        delta_theta = (theta_d - theta_r + 360) % 360\n",
        "\n",
        "        #check which sixth the defensive player lies in\n",
        "        if 0 <= delta_theta < 60:\n",
        "            return 1  # Front sixth\n",
        "        elif 60 <= delta_theta < 180:\n",
        "            return 2  #adjacent sixths (still in front half)\n",
        "        else:\n",
        "            return 3  #otherwise\n",
        "\n",
        "    def potential_move_points(self):\n",
        "        potential_points = []\n",
        "\n",
        "        #create a range of movement values based on speed\n",
        "        range_movement = np.arange(-self.speed, self.speed + 0.1, 0.1)\n",
        "\n",
        "        for dx in range_movement:\n",
        "            for dy in range_movement:\n",
        "                #check if the combined movement is within the speed limit\n",
        "                if np.sqrt(dx**2 + dy**2) <= self.speed:\n",
        "                    #generate potential point by adding delta to current position\n",
        "                    potential_point = (round(self.position[0] + dx, 1), round(self.position[1] + dy, 1))\n",
        "                    potential_points.append(potential_point)\n",
        "\n",
        "        #use set to filter out duplicates\n",
        "        potential_points = list(set(potential_points))\n",
        "\n",
        "        #filter points outside the allowable area\n",
        "        allowed_points = [point for point in potential_points if Point(point).within(self.allowable_area)]\n",
        "\n",
        "        return allowed_points\n",
        "\n",
        "    def potential_move_points_limited_to_five(self):\n",
        "        x, y = self.position\n",
        "\n",
        "        #potential points in the four cardinal directions\n",
        "        potential_points = [\n",
        "            (x, y + self.speed),  # up\n",
        "            (x, y - self.speed),  # down\n",
        "            (x - self.speed, y),  # left\n",
        "            (x + self.speed, y)   # right\n",
        "        ]\n",
        "\n",
        "        #filter points to ensure they lie within the allowable area\n",
        "        valid_points = [Point(p).intersection(self.allowable_area) for p in potential_points]\n",
        "\n",
        "        #if a point lies on the boundary, keep that point. Otherwise, keep the original position.\n",
        "        move_points = [p.coords[0] if p.within(self.allowable_area) or p.touches(self.allowable_area) else (x, y) for p in valid_points]\n",
        "\n",
        "        #add current position to the list\n",
        "        move_points.append((x, y))\n",
        "\n",
        "        #get unique values\n",
        "        move_points = list(set(move_points))\n",
        "\n",
        "        return move_points\n"
      ],
      "metadata": {
        "id": "upjIRXsya5Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def all_available_defensive_moves(defensive_player_list):\n",
        "    all_move_combinations = list(itertools.product(*[player.potential_move_points_limited_to_five() for player in defensive_player_list]))\n",
        "    return all_move_combinations"
      ],
      "metadata": {
        "id": "HYn4LykBa607"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#github blog approach\n",
        "from collections import defaultdict\n",
        "\n",
        "class GameState:\n",
        "    def __init__(self, offensive_players=[], defensive_players=[], time_step=0):\n",
        "        self.offensive_players = offensive_players\n",
        "        self.time_step = time_step\n",
        "        self.defensive_players = defensive_players\n",
        "        self.objective_scores = []\n",
        "\n",
        "    def get_current_offensive_positions(self):\n",
        "        #use the current time_step and the OffensivePlayer objects to get current positions\n",
        "        return [player.calculate_positions(selected_frame = self.time_step) for player in self.offensive_players]\n",
        "\n",
        "    def get_predicted_offensive_positions(self):\n",
        "        #use the next time_step and the OffensivePlayer objects to get predicted positions\n",
        "        return [predict_offensive_position_off(player, self.time_step + 1) for player in self.offensive_players]\n",
        "\n",
        "    def get_time_step(self):\n",
        "        return self.time_step\n",
        "\n",
        "    def objective_function(self):\n",
        "        totalscore = 0\n",
        "        for i in self.offensive_players:\n",
        "            savescore = 10000000\n",
        "            for j in self.defensive_players:\n",
        "                def_positioning = j.relation_to_receiver_direction(i.get_direction_at_time(self.time_step),i.get_position_at_time(self.time_step))\n",
        "                currscore = (j.distance_to(i, self.time_step)**3)*def_positioning\n",
        "                if currscore < savescore:\n",
        "                    savescore = currscore\n",
        "\n",
        "            totalscore += savescore\n",
        "        self.objective_scores.append(totalscore)\n",
        "        return totalscore\n",
        "\n",
        "    def get_legal_actions(self):\n",
        "        available_moves = all_available_defensive_moves(self.defensive_players)\n",
        "        return available_moves\n",
        "\n",
        "    def is_game_over(self):\n",
        "        #check for five consecutive scores above 40 in the latest scores\n",
        "        if len(self.objective_scores) >= 5:\n",
        "            if all(score > 40 for score in self.objective_scores[-5:]):\n",
        "                logging.info(f\"Game over detected at timestep {self.time_step} due to objective scores.\")\n",
        "                return True\n",
        "\n",
        "        #check play length based on number of defensive players\n",
        "        defensive_count = len(self.defensive_players)\n",
        "        if defensive_count >= 8:\n",
        "            play_length = 50\n",
        "        elif defensive_count == 7:\n",
        "            play_length = 40\n",
        "        elif defensive_count == 6:\n",
        "            play_length = 35\n",
        "        else:\n",
        "            play_length = 30\n",
        "        if self.time_step >= play_length:\n",
        "            logging.info(f\"Game over detected at timestep {self.time_step} due to reaching play length.\")\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def game_result(self):\n",
        "        if self.is_game_over():\n",
        "            # Check for five consecutive scores above 40 anywhere in the list\n",
        "            for i in range(len(self.objective_scores) - 4):\n",
        "                if all(score > 40 for score in self.objective_scores[i:i+5]):\n",
        "                    return -1  # Loss for defense\n",
        "            return 1  # Win for defense\n",
        "        return 0 #game ongoing\n",
        "\n",
        "\n",
        "    def move(self, action):\n",
        "        #action will be a tuple of move points, one for each defensive player\n",
        "        #update each player's position based on the action\n",
        "        for player, new_position in zip(self.defensive_players, action):\n",
        "            player.move(new_position)\n",
        "\n",
        "        #create new GameState with the same offensive players, updated defensive players, and incremented time step\n",
        "        new_state = GameState(self.offensive_players, self.defensive_players, self.time_step + 1)\n",
        "\n",
        "        return new_state\n",
        "\n",
        "\n",
        "class MonteCarloTreeSearchNode():\n",
        "    def __init__(self, state, parent=None, parent_action=None):\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.parent_action = parent_action\n",
        "        self.children = []\n",
        "        self._number_of_visits = 0\n",
        "        self._results = defaultdict(int)\n",
        "        self._results[1] = 0\n",
        "        self._results[-1] = 0\n",
        "        self._untried_actions = None\n",
        "        self._untried_actions = self.untried_actions()\n",
        "        return\n",
        "\n",
        "\n",
        "    def untried_actions(self):\n",
        "        self._untried_actions = self.state.get_legal_actions()\n",
        "        return self._untried_actions\n",
        "\n",
        "\n",
        "    def q(self):\n",
        "        wins = self._results[1]\n",
        "        loses = self._results[-1]\n",
        "        return wins - loses\n",
        "\n",
        "\n",
        "    def n(self):\n",
        "        return self._number_of_visits\n",
        "\n",
        "\n",
        "    def expand(self):\n",
        "        action = self._untried_actions.pop()\n",
        "        next_state = self.state.move(action)\n",
        "        child_node = MonteCarloTreeSearchNode(\n",
        "            next_state, parent=self, parent_action=action)\n",
        "        self.children.append(child_node)\n",
        "        logging.info(f\"Expanding node at timestep {self.state.get_time_step()} using action {action}.\")\n",
        "        return child_node\n",
        "\n",
        "\n",
        "    def is_terminal_node(self):\n",
        "        if self.state.is_game_over():\n",
        "            logging.info(f\"Node at timestep {self.state.get_time_step()} is terminal.\")\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "\n",
        "    def rollout(self):\n",
        "        current_rollout_state = self.state\n",
        "        while not current_rollout_state.is_game_over():\n",
        "            possible_moves = current_rollout_state.get_legal_actions()\n",
        "            action = self.rollout_policy(possible_moves)\n",
        "            logging.info(f\"Rollout: Taking action {action} at timestep {current_rollout_state.get_time_step()}.\")\n",
        "            current_rollout_state = current_rollout_state.move(action)\n",
        "        result = current_rollout_state.game_result()\n",
        "        logging.info(f\"Rollout finished with result: {result} at timestep {self.state.get_time_step()}.\")\n",
        "        return result\n",
        "\n",
        "\n",
        "    def backpropagate(self, result):\n",
        "        self._number_of_visits += 1.\n",
        "        self._results[result] += 1.\n",
        "        logging.info(f\"Backpropagating with result: {result} from node at timestep {self.state.get_time_step()}.\")\n",
        "        if self.parent:\n",
        "            self.parent.backpropagate(result)\n",
        "\n",
        "\n",
        "    def is_fully_expanded(self):\n",
        "        return len(self._untried_actions) == 0\n",
        "\n",
        "\n",
        "    def best_child(self, c_param=100):\n",
        "        choices_weights = [(c.q() / c.n()) + c_param * np.sqrt((2 * np.log(self.n()) / c.n())) for c in self.children]\n",
        "        return self.children[np.argmax(choices_weights)]\n",
        "\n",
        "\n",
        "    def rollout_policy(self, possible_moves):\n",
        "        return possible_moves[np.random.randint(len(possible_moves))]\n",
        "\n",
        "\n",
        "    def _tree_policy(self):\n",
        "        current_node = self\n",
        "        while not current_node.is_terminal_node():\n",
        "            if not current_node.is_fully_expanded():\n",
        "                return current_node.expand()\n",
        "            else:\n",
        "                logging.info(f\"Node at timestep {current_node.state.get_time_step()} is fully expanded.\")\n",
        "                current_node = current_node.best_child()\n",
        "        return current_node\n",
        "\n",
        "\n",
        "    def best_action(self):\n",
        "        simulation_no = 1000\n",
        "        found_win = False\n",
        "        for i in range(simulation_no):\n",
        "            logging.info(f\"Starting simulation {i + 1} of {simulation_no}...\")\n",
        "            v = self._tree_policy()\n",
        "            reward = v.rollout()\n",
        "            v.backpropagate(reward)\n",
        "\n",
        "            # Check if the game resulted in a win (reward = 1)\n",
        "            if reward == 1:\n",
        "                found_win = True\n",
        "                logging.info(f\"Stopping simulation after finding a win at simulation {i + 1}.\")\n",
        "                break\n",
        "\n",
        "        if found_win:\n",
        "            best_action_sequence = self.get_best_action_sequence()\n",
        "            if len(best_action_sequence) == 30:  # Ensure it's 30 actions long\n",
        "                return self  # Return the current node\n",
        "            else:\n",
        "                logging.warning(f\"Unexpected number of actions: {len(best_action_sequence)}\")\n",
        "                return None\n",
        "        else:\n",
        "            return self.best_child(c_param=0.)\n",
        "\n",
        "\n",
        "    def get_path_actions(self):\n",
        "        current_node = self\n",
        "        path_actions = []\n",
        "        while current_node.parent is not None:\n",
        "            path_actions.append(current_node.parent_action)\n",
        "            current_node = current_node.parent\n",
        "        return path_actions[::-1]  # Reverse to get actions from root to leaf\n",
        "\n",
        "\n",
        "    def get_best_action_sequence(self):\n",
        "        current_node = self\n",
        "        best_actions = []\n",
        "\n",
        "        while current_node.children:  # while there are children nodes\n",
        "            next_node = current_node.best_child(c_param=0.)\n",
        "            best_actions.append(next_node.parent_action)\n",
        "            current_node = next_node\n",
        "\n",
        "        return best_actions"
      ],
      "metadata": {
        "id": "9sgGANRxa8JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#offensive players\n",
        "opl1 = [(20, 20), (20, 22), (10, 24), (12, 50)]\n",
        "opl2 = [(-20, 20), (-20, 27), (-15, 40)]\n",
        "opl3 = [(-16, 19), (-16, 25), (-18, 23)]\n",
        "opl4 = [(2, 15), (16, 17), (23, 23)]\n",
        "\n",
        "receiver1 = OffensivePlayer(opl1, 1) # 1 yard per 0.1 seconds = 10s 100yd dash\n",
        "receiver2 = OffensivePlayer(opl2, 0.8)\n",
        "receiver3 = OffensivePlayer(opl3, 0.9)\n",
        "receiver4 = OffensivePlayer(opl4, 0.8)\n",
        "\n",
        "#defensive players\n",
        "allowable_area2 = Polygon([(-27,20), (27,20), (27,100), (-27,100)])\n",
        "defplayer1 = DefensivePlayer((20,21), 0.9, allowable_area2)#cb1\n",
        "defplayer2 = DefensivePlayer((-20,21), 1, allowable_area2)#cb2\n",
        "defplayer3 = DefensivePlayer((-15,23), 0.9, allowable_area2)#ncb\n",
        "defplayer4 = DefensivePlayer((0,25), 0.8, allowable_area2)#lb"
      ],
      "metadata": {
        "id": "B2cX6S4ua9mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run MCTS\n",
        "\n",
        "#create instances of players\n",
        "offensive_players = [receiver1,receiver2,receiver3,receiver4]\n",
        "defensive_players = [defplayer1,defplayer2,defplayer3,defplayer4]\n",
        "\n",
        "#backup initialization\n",
        "offensive_players = [receiver1,receiver2]\n",
        "defensive_players = [defplayer1,defplayer2]\n",
        "\n",
        "#create initial game state\n",
        "initial_state = GameState(offensive_players=offensive_players, defensive_players=defensive_players)\n",
        "\n",
        "#create root node for MCTS\n",
        "root_node = MonteCarloTreeSearchNode(initial_state)\n",
        "\n",
        "best_node = root_node.best_action()\n",
        "if best_node is not None:\n",
        "    best_action_sequence = best_node.get_best_action_sequence()\n",
        "    print(best_action_sequence)\n",
        "else:\n",
        "    print(\"No winning sequence found or the winning sequence was not 30 actions long.\")"
      ],
      "metadata": {
        "id": "1wfZh1h9a_gl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}